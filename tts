#!/usr/bin/env python3
import time
import hashlib
import math
import sys
import os
import tempfile
import subprocess
import argparse
import io
import threading
import pickle
import glob
import enum
import logging

import gtts
import pyperclip

# Removing bad substitution of M. to Monsieur
gtts.tokenizer.symbols.SUB_PAIRS = []


def add_arguments(parser):
    source_group = parser.add_mutually_exclusive_group()
    source_group.add_argument("-c", "--clipboard", action="store_true")
    source_group.add_argument(
        "-f",
        "--file",
        dest="infile",
        type=str,
        help='Input file of text to read. "-" for stdin.',
    )
    parser.add_argument("text", type=str, nargs="*")
    parser.add_argument("-l", "--loop", action="store_true")
    parser.add_argument("--no-cache", dest="cache", action="store_false")
    parser.add_argument("--clear-cache", action="store_true")
    parser.add_argument("-s", "--start-line", type=int, default=0)
    parser.add_argument(
        "-v",
        "--verbosity",
        choices=("CRITICAL", "ERROR", "WARNING", "INFO", "DEBUG", "NOTSET"),
        default="WARNING",
    )

    return parser


class LineState(enum.Enum):
    r"""
    FREE --> DISPATCHED --> READY
                        \
                         -> ERROR
    """
    FREE = enum.auto()  # Nothing has been done with this line yet
    DISPATCHED = enum.auto()  # Line has been given to a worker thread
    READY = enum.auto()  # Line has been converted and is ready to read
    ERROR = enum.auto()  # Line conversion failed


class Line(object):
    def __init__(self, text):
        self.text = text.strip()
        self.state = LineState.FREE
        self.error = None
        self.mp3bytes = None

    def __eq__(self, other):
        return self.text == other.text

    def __hash__(self):
        return hash(self.text)

    def play(self):
        if self.state == LineState.READY:
            self.__play_gtts_mp3()
        elif self.state == LineState.ERROR:
            self.__play_espeak_fallback()
        else:
            raise RuntimeError(
                'Tried to play not ready line "{}" with state "{}"'.format(
                    self.text, self.state
                )
            )

    def __play_gtts_mp3(self):
        with open("/dev/null") as devnull:
            p = subprocess.Popen(
                ["play", "-t", "mp3", "-"], stderr=devnull, stdin=subprocess.PIPE
            )
            p.stdin.write(self.mp3bytes)
            p.stdin.close()
            p.wait()

    def __play_espeak_fallback(self):
        msg = (
            'Tried to play line "%s" with state "%s". The error was "%s". '
            "Falling back to espeak."
        )
        logger = logging.getLogger("tts.Line")
        logger.warning(msg, self.text, str(self.state), str(self.error))
        p = subprocess.Popen(["espeak"], stdin=subprocess.PIPE)
        p.stdin.write(self.text.encode())
        p.stdin.close()
        p.wait()

    def convert(self):
        try:
            tts = gtts.gTTS(self.text)
            data = io.BytesIO()
            tts.write_to_fp(data)
            data.seek(0)
            self.mp3bytes = data.getvalue()
            self.state = LineState.READY
        except Exception as e:
            self.error = e
            self.state = LineState.ERROR
            logger = logging.getLogger("tts.Line")
            logger.warning('Error "%s" when converting line "%s"', str(e), self.text)

    def copy_for_pickling(self):
        copy = Line(self.text)
        if self.state == LineState.READY:
            copy.mp3bytes = self.mp3bytes
            copy.state = LineState.READY
        return copy


class Lines(object):
    CACHE_WARNING_SIZE = 1e10  # 10 GB
    CACHE_DIR = os.sep.join([os.getenv("HOME", None), ".cache", "tts"])
    CACHE_FILENAME_PATTERN = "tts_cache_{hex_hash}.pickle"
    CACHE_WRITE_PERIOD = 60  # seconds

    def __init__(self, text, cache=True, clear_cache=False):
        self.__cache = cache
        self.__cache_path = None
        self.__cache_is_stale = False
        self.__lines = tuple(Line(l) for l in text.split("\n") if l.strip())
        self.handle_cache_size(clear_cache)
        self.__logger = logging.getLogger("tts.Lines")
        if self.__cache:
            self.read_cache()

    def finalize(self):
        if self and self.__cache:
            self.write_cache()

    def __getitem__(self, idx):
        return self.__lines[idx]

    def __len__(self):
        return len(self.__lines)

    @classmethod
    def handle_cache_size(cls, clear_cache):
        """If clear_cache, deletes all cache entries. Otherwise, print
        a warning if the overall cache size is too big

        """
        logger = logging.getLogger("tts.Lines")
        if os.path.exists(cls.CACHE_DIR):
            glob_pattern = os.path.sep.join(
                [cls.CACHE_DIR, cls.CACHE_FILENAME_PATTERN.format(hex_hash="*")]
            )
            cache_paths = glob.glob(glob_pattern)
            if clear_cache:
                logger.debug("Clearing cache")
                for path in cache_paths:
                    os.remove(path)
            else:
                total_bytes = sum(os.path.getsize(path) for path in cache_paths)
                total_bytes_string = cls.human_filesize(total_bytes)
                logger.info("Total cache size: %s", total_bytes_string)
                if total_bytes > cls.CACHE_WARNING_SIZE:
                    msg_fmt = (
                        'Total size of tts cache at path "{}" has size {}, exceeding '
                        "the warning limit of {}. Run tts --clear-cache to delete all "
                        "cached files."
                    )
                    msg = msg_fmt.format(
                        cls.CACHE_DIR,
                        total_bytes_string,
                        cls.human_filesize(cls.CACHE_WARNING_SIZE),
                    )
                    logger.warning(msg)

    def read_cache(self):
        self.__logger.debug("looking for cache to read")
        hex_digits = 8
        stripped_text = "\n".join(l.text for l in self.__lines)
        curr_hash = int(
            hashlib.md5(stripped_text.encode()).hexdigest()[:hex_digits], 16
        )
        hex_pattern = "{{:0{}x}}".format(hex_digits)
        while True:
            hex_hash = hex_pattern.format(curr_hash)
            self.__cache_path = os.sep.join(
                [self.CACHE_DIR, self.CACHE_FILENAME_PATTERN.format(hex_hash=hex_hash)]
            )
            if os.path.exists(self.__cache_path):
                with open(self.__cache_path, "r+b") as f:
                    cached_lines = pickle.load(f)
                    if self.__lines == cached_lines:
                        # Found existing match
                        self.__lines = cached_lines
                        self.__logger.debug("using existing cache %s", self.__cache_path)
                        break
                    else:
                        # Hash collision
                        curr_hash += 1
                        self.__logger.debug("cache hash collision with %s", self.__cache_path)
            else:
                self.__logger.debug("using new cache location %s", self.__cache_path)
                break

    def write_cache(self):
        self.__logger.debug("Writing cache")
        subprocess.call(["mkdir", "-p", self.CACHE_DIR])
        for line in self.__lines:
            if line.state != LineState.READY:
                line.state = LineState.FREE
            line.error = None
        # Atomic write
        pickle_path = self.__cache_path + ".part"
        with open(pickle_path, "w+b") as f:
            pickle.dump(self.__lines, f)
        os.rename(pickle_path, self.__cache_path)
        self.__logger.debug("Done writing cache")

    @staticmethod
    def human_filesize(bytes_):
        units = ["bytes", "kB", "MB", "GB", "TB", "PB"]
        power = 0
        for power, unit in enumerate(units):
            if bytes_ < 1024 ** (power + 1):
                break
        if power == 0:
            return "{} bytes".format(bytes_)
        return "{:.2f} {}".format(bytes_ / 1024.0 ** power, unit)


class WorkerState(enum.Enum):
    r"""
    INIT --> RUNNING --> DONE --> CLOSED

    """
    INIT = enum.auto()  # Worker created
    RUNNING = enum.auto()  # Threads have been started
    DONE = enum.auto()  # Producer threads have been joined; work is done
    CLOSED = enum.auto()  # Runner thread is joined; close has been called


class Worker(object):
    def __init__(self, lines, thread_count=3, start_idx=0, autostart=True, cache=True):
        self.__lines = lines
        self.__reader_idx = start_idx
        self.__lock = threading.Lock()
        self.__has_been_closed = False
        self.__runner = threading.Thread(target=self.__run, args=(thread_count,))
        self.__shutdown_flag = False
        self.__logger = logging.getLogger("tts.Worker")
        self.state = WorkerState.INIT
        if autostart:
            self.start()

    def start(self):
        self.__runner.start()

    def __run(self, thread_count):
        self.__logger.debug("Starting runner thread")
        self.state = WorkerState.RUNNING
        producers = [
            threading.Thread(target=self.__produce) for __ in range(thread_count)
        ]
        for t in producers:
            t.start()
        for t in producers:
            t.join()
        self.__logger.debug("Done joining producers")
        self.__lines.finalize()
        self.state = WorkerState.DONE
        self.__logger.debug("Leaving runner thread")

    def close(self):
        if self.state == WorkerState.CLOSED:
            self.__logger.debug("Worker was already closed")
            return
        self.__logger.debug("Closing worker")
        self.__shutdown_flag = True
        self.__runner.join()
        self.state = WorkerState.CLOSED
        self.__logger.debug("Worker has been closed")

    def __produce(self):
        self.__logger.debug("Starting producer thread")
        for line in self:
            if self.__has_been_closed:
                return
            line.convert()
        self.__logger.debug("Leaving producer thread")

    def set_reader_index(self, idx):
        self.__lock.acquire()
        try:
            self.__reader_idx = idx
            self.__logger.debug("reader_idx updated to %d", self.__reader_idx)
        finally:
            self.__lock.release()

    def __iter__(self):
        return self

    def __next__(self):
        if self.__shutdown_flag:
            raise StopIteration

        self.__lock.acquire()
        try:
            reader_idx = self.__reader_idx
        finally:
            self.__lock.release()

        line_order = self.__lines[reader_idx:] + tuple(
            reversed(self.__lines[:reader_idx])
        )

        for line in line_order:
            if line.state == LineState.FREE:
                line.state = LineState.DISPATCHED
                return line
        raise StopIteration

    def __del__(self):
        self.close()


class SequentialReader(object):
    def __init__(self, lines, worker, start_idx=0, loop=False, autostart=True):
        self.__lines = lines
        self.__worker = worker
        self.__reader_idx = start_idx
        self.__loop = loop
        self.__worker.set_reader_index(self.__reader_idx)
        self.__logger = logging.getLogger("tts.Reader")
        if autostart:
            self.start()

    def start(self):
        if not self.__lines:
            return
        while True:
            line = self.__lines[self.__reader_idx]
            self.__logger.info("Starting line %d", self.__reader_idx)
            while line.state in [LineState.FREE, LineState.DISPATCHED]:
                time.sleep(0.1)
            if line.state in [LineState.READY, LineState.ERROR]:
                line.play()
            else:
                msg = 'Tried to play line "{}" w/ state "{}". This should never happen.'
                raise RuntimeError(msg.format(line.text, line.state))
            self.__reader_idx += 1
            if self.__reader_idx >= len(self.__lines):
                if self.__loop:
                    self.__reader_idx = self.__reader_idx % len(self.__lines)
                else:
                    break
            self.__worker.set_reader_index(self.__reader_idx)


def main(infile, loop, text, cache, clear_cache, clipboard, verbosity, start_line):
    logging.basicConfig(level=verbosity)
    logger = logging.getLogger("tts.main")

    if infile:
        if infile == "-":
            all_text = sys.stdin.read()
        else:
            with open(infile) as f:
                all_text = f.read()
    elif clipboard:
        all_text = pyperclip.paste()
    else:
        all_text = " ".join(text)

    lines = Lines(all_text, cache=cache, clear_cache=clear_cache)

    worker = Worker(lines)

    try:
        reader = SequentialReader(lines, worker, start_idx=start_line, loop=loop)
    except KeyboardInterrupt:
        logger.info("Caught keyboard interrupt")
        print("Shutting down...")
    finally:
        logger.debug("Calling worker.close")
        worker.close()

    logger.debug("Exiting")
    return 0


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="TTS program backed by Google TTS with an espeak fallback"
    )
    add_arguments(parser)
    args = parser.parse_args()
    if args.text and (args.infile or args.clipboard):
        parser.error("Arguments text, infile, and clipboard are mutually exclusive.")
    sys.exit(main(**args.__dict__))
